{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from torchvision.models import resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(input_path, size=(224, 224)):\n",
    "    # Abrir la imagen\n",
    "    image = Image.open(input_path).convert(\"L\")  # Convertir a escala de grises\n",
    "    \n",
    "    # Obtener tamaño original\n",
    "    original_width, original_height = image.size\n",
    "    aspect_ratio = original_width / original_height\n",
    "    \n",
    "    # Calcular nuevo tamaño\n",
    "    if aspect_ratio > 1:\n",
    "        # Imagen más ancha que alta\n",
    "        new_width = size[0]\n",
    "        new_height = int(new_width / aspect_ratio)\n",
    "    else:\n",
    "        # Imagen más alta que ancha\n",
    "        new_height = size[1]\n",
    "        new_width = int(new_height * aspect_ratio)\n",
    "    \n",
    "    # Redimensionar la imagen manteniendo la relación de aspecto\n",
    "    # si la imagen es mas chica que el tamaño deseado, uso interpolación LANCZOS, sino LINEAL\n",
    "    if original_width < size[0] or original_height < size[1]:\n",
    "        resized_image = image.resize((new_width, new_height), Image.LANCZOS)\n",
    "    else:\n",
    "        resized_image = image.resize((new_width, new_height), Image.LINEAR)\n",
    "    \n",
    "    # Crear un nuevo fondo de 224x224 y pegar la imagen redimensionada en el centro\n",
    "    new_image = Image.new(\"L\", size)\n",
    "    new_image.paste(resized_image, ((size[0] - new_width) // 2, (size[1] - new_height) // 2))\n",
    "    \n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original image size: (178, 218)\n",
      "resized image size: (224, 224)\n"
     ]
    }
   ],
   "source": [
    "# show original image\n",
    "image = Image.open(\"CelebA/celebA/img_align_celeba/img_align_celeba/125478.jpg\")\n",
    "image.show()\n",
    "\n",
    "# image size\n",
    "print(\"original image size:\", image.size)\n",
    "\n",
    "# resize image\n",
    "resized_image = resize_image(\"CelebA/celebA/img_align_celeba/img_align_celeba/125478.jpg\")\n",
    "resized_image.show()\n",
    "\n",
    "# resized image size\n",
    "print(\"resized image size:\", resized_image.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original image pixel range: (4, 0, 0) (255, 226, 234)\n",
      "resized image pixel range: 0 236\n"
     ]
    }
   ],
   "source": [
    "# range of pixel values of the original image\n",
    "print(\"original image pixel range:\", min(image.getdata()), max(image.getdata()))\n",
    "\n",
    "# range of pixel values of the resized image\n",
    "print(\"resized image pixel range:\", min(resized_image.getdata()), max(resized_image.getdata()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperResolutionResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SuperResolutionResNet, self).__init__()\n",
    "        # Cargar el modelo preentrenado resnet18\n",
    "        self.resnet = models.resnet18(pretrained=True)\n",
    "        \n",
    "        # Modificar la primera capa para aceptar una sola canal (imágenes en escala de grises)\n",
    "        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        \n",
    "        # Eliminar la última capa (clasificación)\n",
    "        self.resnet = nn.Sequential(*list(self.resnet.children())[:-2])\n",
    "        \n",
    "        # Añadir capas para aumentar la resolución\n",
    "        self.upconv1 = nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1)\n",
    "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1)\n",
    "        self.upconv3 = nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1)\n",
    "        self.upconv4 = nn.ConvTranspose2d(64, 1, kernel_size=4, stride=2, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        x = self.relu(self.upconv1(x))\n",
    "        x = self.relu(self.upconv2(x))\n",
    "        x = self.relu(self.upconv3(x))\n",
    "        x = self.upconv4(x)\n",
    "        return x\n",
    "\n",
    "def resize_image(input_path, size=(224, 224)):\n",
    "    # Abrir la imagen\n",
    "    image = Image.open(input_path).convert(\"L\")  # Convertir a escala de grises\n",
    "    \n",
    "    # Obtener tamaño original\n",
    "    original_width, original_height = image.size\n",
    "    aspect_ratio = original_width / original_height\n",
    "    \n",
    "    # Calcular nuevo tamaño\n",
    "    if aspect_ratio > 1:\n",
    "        # Imagen más ancha que alta\n",
    "        new_width = size[0]\n",
    "        new_height = int(new_width / aspect_ratio)\n",
    "    else:\n",
    "        # Imagen más alta que ancha\n",
    "        new_height = size[1]\n",
    "        new_width = int(new_height * aspect_ratio)\n",
    "    \n",
    "    # Redimensionar la imagen manteniendo la relación de aspecto\n",
    "    # si la imagen es mas chica que el tamaño deseado, uso interpolación LANCZOS, sino LINEAL\n",
    "    if original_width < size[0] or original_height < size[1]:\n",
    "        resized_image = image.resize((new_width, new_height), Image.LANCZOS)\n",
    "    else:\n",
    "        resized_image = image.resize((new_width, new_height), Image.LINEAR)\n",
    "    \n",
    "    # Crear un nuevo fondo de 224x224 y pegar la imagen redimensionada en el centro\n",
    "    new_image = Image.new(\"L\", size)\n",
    "    new_image.paste(resized_image, ((size[0] - new_width) // 2, (size[1] - new_height) // 2))\n",
    "    \n",
    "    return new_image\n",
    "\n",
    "def super_resolve_image(image, model, device):\n",
    "    # Convertir imagen a tensor y añadir un canal\n",
    "    image = transforms.ToTensor()(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Aumentar la resolución usando el modelo de super-resolución\n",
    "    with torch.no_grad():\n",
    "        sr_image = model(image)\n",
    "    \n",
    "    # Convertir de nuevo a PIL\n",
    "    sr_image = sr_image.squeeze(0).cpu().numpy()\n",
    "    sr_image = (sr_image - sr_image.min()) / (sr_image.max() - sr_image.min())  # Normalizar\n",
    "    sr_image = (sr_image * 255).astype(np.uint8)  # Escalar a [0, 255]\n",
    "    sr_image = Image.fromarray(sr_image[0])  # Convertir el primer canal a PIL\n",
    "    return sr_image\n",
    "\n",
    "def process_image(input_path, output_path):\n",
    "    # Configuración del dispositivo\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Paso 1: Redimensionar la imagen manteniendo la relación de aspecto\n",
    "    resized_image = resize_image(input_path, size=(224, 224))\n",
    "    \n",
    "    # Crear el modelo de super-resolución y cargarlo en el dispositivo\n",
    "    model = SuperResolutionResNet().to(device)\n",
    "    \n",
    "    # Paso 2: Mejorar la resolución de la imagen redimensionada\n",
    "    final_image = super_resolve_image(resized_image, model, device)\n",
    "    \n",
    "    # Guardar la imagen final\n",
    "    final_image.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_image(\"CelebA/celebA/img_align_celeba/img_align_celeba/125479.jpg\", \"resnet18_output_image.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleSRCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleSRCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=9, padding=4)\n",
    "        self.conv2 = nn.Conv2d(64, 32, kernel_size=1, padding=0)\n",
    "        self.conv3 = nn.Conv2d(32, 1, kernel_size=5, padding=2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        return x\n",
    "\n",
    "def super_resolve_image(image, model):\n",
    "    # Convertir imagen a tensor y añadir un canal\n",
    "    image = transforms.ToTensor()(image).unsqueeze(0)\n",
    "    \n",
    "    # Aumentar la resolución usando el modelo de super-resolución\n",
    "    with torch.no_grad():\n",
    "        sr_image = model(image)\n",
    "    \n",
    "    # Convertir de nuevo a PIL\n",
    "    sr_image = transforms.ToPILImage()(sr_image.squeeze(0))\n",
    "    \n",
    "    return sr_image\n",
    "\n",
    "def process_image(input_path, output_path):\n",
    "    # Paso 1: Redimensionar la imagen manteniendo la relación de aspecto\n",
    "    resized_image = resize_image(input_path, size=(224, 224))\n",
    "    \n",
    "    # Crear el modelo de super-resolución\n",
    "    model = SimpleSRCNN()\n",
    "    \n",
    "    # Cargar pesos preentrenados si tienes alguno (esto es solo un placeholder)\n",
    "    # model.load_state_dict(torch.load('path_to_pretrained_weights.pth'))\n",
    "    \n",
    "    # Paso 2: Mejorar la resolución de la imagen redimensionada\n",
    "    final_image = super_resolve_image(resized_image, model)\n",
    "    \n",
    "    # Guardar la imagen final\n",
    "    final_image.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:53] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    }
   ],
   "source": [
    "process_image(\"CelebA/celebA/img_align_celeba/img_align_celeba/125479.jpg\", \"output_image.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for RRDBNet:\n\tMissing key(s) in state_dict: \"conv_first.weight\", \"conv_first.bias\", \"body.0.rdb1.conv1.weight\", \"body.0.rdb1.conv1.bias\", \"body.0.rdb1.conv2.weight\", \"body.0.rdb1.conv2.bias\", \"body.0.rdb1.conv3.weight\", \"body.0.rdb1.conv3.bias\", \"body.0.rdb1.conv4.weight\", \"body.0.rdb1.conv4.bias\", \"body.0.rdb1.conv5.weight\", \"body.0.rdb1.conv5.bias\", \"body.0.rdb2.conv1.weight\", \"body.0.rdb2.conv1.bias\", \"body.0.rdb2.conv2.weight\", \"body.0.rdb2.conv2.bias\", \"body.0.rdb2.conv3.weight\", \"body.0.rdb2.conv3.bias\", \"body.0.rdb2.conv4.weight\", \"body.0.rdb2.conv4.bias\", \"body.0.rdb2.conv5.weight\", \"body.0.rdb2.conv5.bias\", \"body.0.rdb3.conv1.weight\", \"body.0.rdb3.conv1.bias\", \"body.0.rdb3.conv2.weight\", \"body.0.rdb3.conv2.bias\", \"body.0.rdb3.conv3.weight\", \"body.0.rdb3.conv3.bias\", \"body.0.rdb3.conv4.weight\", \"body.0.rdb3.conv4.bias\", \"body.0.rdb3.conv5.weight\", \"body.0.rdb3.conv5.bias\", \"body.1.rdb1.conv1.weight\", \"body.1.rdb1.conv1.bias\", \"body.1.rdb1.conv2.weight\", \"body.1.rdb1.conv2.bias\", \"body.1.rdb1.conv3.weight\", \"body.1.rdb1.conv3.bias\", \"body.1.rdb1.conv4.weight\", \"body.1.rdb1.conv4.bias\", \"body.1.rdb1.conv5.weight\", \"body.1.rdb1.conv5.bias\", \"body.1.rdb2.conv1.weight\", \"body.1.rdb2.conv1.bias\", \"body.1.rdb2.conv2.weight\", \"body.1.rdb2.conv2.bias\", \"body.1.rdb2.conv3.weight\", \"body.1.rdb2.conv3.bias\", \"body.1.rdb2.conv4.weight\", \"body.1.rdb2.conv4.bias\", \"body.1.rdb2.conv5.weight\", \"body.1.rdb2.conv5.bias\", \"body.1.rdb3.conv1.weight\", \"body.1.rdb3.conv1.bias\", \"body.1.rdb3.conv2.weight\", \"body.1.rdb3.conv2.bias\", \"body.1.rdb3.conv3.weight\", \"body.1.rdb3.conv3.bias\", \"body.1.rdb3.conv4.weight\", \"body.1.rdb3.conv4.bias\", \"body.1.rdb3.conv5.weight\", \"body.1.rdb3.conv5.bias\", \"body.2.rdb1.conv1.weight\", \"body.2.rdb1.conv1.bias\", \"body.2.rdb1.conv2.weight\", \"body.2.rdb1.conv2.bias\", \"body.2.rdb1.conv3.weight\", \"body.2.rdb1.conv3.bias\", \"body.2.rdb1.conv4.weight\", \"body.2.rdb1.conv4.bias\", \"body.2.rdb1.conv5.weight\", \"body.2.rdb1.conv5.bias\", \"body.2.rdb2.conv1.weight\", \"body.2.rdb2.conv1.bias\", \"body.2.rdb2.conv2.weight\", \"body.2.rdb2.conv2.bias\", \"body.2.rdb2.conv3.weight\", \"body.2.rdb2.conv3.bias\", \"body.2.rdb2.conv4.weight\", \"body.2.rdb2.conv4.bias\", \"body.2.rdb2.conv5.weight\", \"body.2.rdb2.conv5.bias\", \"body.2.rdb3.conv1.weight\", \"body.2.rdb3.conv1.bias\", \"body.2.rdb3.conv2.weight\", \"body.2.rdb3.conv2.bias\", \"body.2.rdb3.conv3.weight\", \"body.2.rdb3.conv3.bias\", \"body.2.rdb3.conv4.weight\", \"body.2.rdb3.conv4.bias\", \"body.2.rdb3.conv5.weight\", \"body.2.rdb3.conv5.bias\", \"body.3.rdb1.conv1.weight\", \"body.3.rdb1.conv1.bias\", \"body.3.rdb1.conv2.weight\", \"body.3.rdb1.conv2.bias\", \"body.3.rdb1.conv3.weight\", \"body.3.rdb1.conv3.bias\", \"body.3.rdb1.conv4.weight\", \"body.3.rdb1.conv4.bias\", \"body.3.rdb1.conv5.weight\", \"body.3.rdb1.conv5.bias\", \"body.3.rdb2.conv1.weight\", \"body.3.rdb2.conv1.bias\", \"body.3.rdb2.conv2.weight\", \"body.3.rdb2.conv2.bias\", \"body.3.rdb2.conv3.weight\", \"body.3.rdb2.conv3.bias\", \"body.3.rdb2.conv4.weight\", \"body.3.rdb2.conv4.bias\", \"body.3.rdb2.conv5.weight\", \"body.3.rdb2.conv5.bias\", \"body.3.rdb3.conv1.weight\", \"body.3.rdb3.conv1.bias\", \"body.3.rdb3.conv2.weight\", \"body.3.rdb3.conv2.bias\", \"body.3.rdb3.conv3.weight\", \"body.3.rdb3.conv3.bias\", \"body.3.rdb3.conv4.weight\", \"body.3.rdb3.conv4.bias\", \"body.3.rdb3.conv5.weight\", \"body.3.rdb3.conv5.bias\", \"body.4.rdb1.conv1.weight\", \"body.4.rdb1.conv1.bias\", \"body.4.rdb1.conv2.weight\", \"body.4.rdb1.conv2.bias\", \"body.4.rdb1.conv3.weight\", \"body.4.rdb1.conv3.bias\", \"body.4.rdb1.conv4.weight\", \"body.4.rdb1.conv4.bias\", \"body.4.rdb1.conv5.weight\", \"body.4.rdb1.conv5.bias\", \"body.4.rdb2.conv1.weight\", \"body.4.rdb2.conv1.bias\", \"body.4.rdb2.conv2.weight\", \"body.4.rdb2.conv2.bias\", \"body.4.rdb2.conv3.weight\", \"body.4.rdb2.conv3.bias\", \"body.4.rdb2.conv4.weight\", \"body.4.rdb2.conv4.bias\", \"body.4.rdb2.conv5.weight\", \"body.4.rdb2.conv5.bias\", \"body.4.rdb3.conv1.weight\", \"body.4.rdb3.conv1.bias\", \"body.4.rdb3.conv2.weight\", \"body.4.rdb3.conv2.bias\", \"body.4.rdb3.conv3.weight\", \"body.4.rdb3.conv3.bias\", \"body.4.rdb3.conv4.weight\", \"body.4.rdb3.conv4.bias\", \"body.4.rdb3.conv5.weight\", \"body.4.rdb3.conv5.bias\", \"body.5.rdb1.conv1.weight\", \"body.5.rdb1.conv1.bias\", \"body.5.rdb1.conv2.weight\", \"body.5.rdb1.conv2.bias\", \"body.5.rdb1.conv3.weight\", \"body.5.rdb1.conv3.bias\", \"body.5.rdb1.conv4.weight\", \"body.5.rdb1.conv4.bias\", \"body.5.rdb1.conv5.weight\", \"body.5.rdb1.conv5.bias\", \"body.5.rdb2.conv1.weight\", \"body.5.rdb2.conv1.bias\", \"body.5.rdb2.conv2.weight\", \"body.5.rdb2.conv2.bias\", \"body.5.rdb2.conv3.weight\", \"body.5.rdb2.conv3.bias\", \"body.5.rdb2.conv4.weight\", \"body.5.rdb2.conv4.bias\", \"body.5.rdb2.conv5.weight\", \"body.5.rdb2.conv5.bias\", \"body.5.rdb3.conv1.weight\", \"body.5.rdb3.conv1.bias\", \"body.5.rdb3.conv2.weight\", \"body.5.rdb3.conv2.bias\", \"body.5.rdb3.conv3.weight\", \"body.5.rdb3.conv3.bias\", \"body.5.rdb3.conv4.weight\", \"body.5.rdb3.conv4.bias\", \"body.5.rdb3.conv5.weight\", \"body.5.rdb3.conv5.bias\", \"body.6.rdb1.conv1.weight\", \"body.6.rdb1.conv1.bias\", \"body.6.rdb1.conv2.weight\", \"body.6.rdb1.conv2.bias\", \"body.6.rdb1.conv3.weight\", \"body.6.rdb1.conv3.bias\", \"body.6.rdb1.conv4.weight\", \"body.6.rdb1.conv4.bias\", \"body.6.rdb1.conv5.weight\", \"body.6.rdb1.conv5.bias\", \"body.6.rdb2.conv1.weight\", \"body.6.rdb2.conv1.bias\", \"body.6.rdb2.conv2.weight\", \"body.6.rdb2.conv2.bias\", \"body.6.rdb2.conv3.weight\", \"body.6.rdb2.conv3.bias\", \"body.6.rdb2.conv4.weight\", \"body.6.rdb2.conv4.bias\", \"body.6.rdb2.conv5.weight\", \"body.6.rdb2.conv5.bias\", \"body.6.rdb3.conv1.weight\", \"body.6.rdb3.conv1.bias\", \"body.6.rdb3.conv2.weight\", \"body.6.rdb3.conv2.bias\", \"body.6.rdb3.conv3.weight\", \"body.6.rdb3.conv3.bias\", \"body.6.rdb3.conv4.weight\", \"body.6.rdb3.conv4.bias\", \"body.6.rdb3.conv5.weight\", \"body.6.rdb3.conv5.bias\", \"body.7.rdb1.conv1.weight\", \"body.7.rdb1.conv1.bias\", \"body.7.rdb1.conv2.weight\", \"body.7.rdb1.conv2.bias\", \"body.7.rdb1.conv3.weight\", \"body.7.rdb1.conv3.bias\", \"body.7.rdb1.conv4.weight\", \"body.7.rdb1.conv4.bias\", \"body.7.rdb1.conv5.weight\", \"body.7.rdb1.conv5.bias\", \"body.7.rdb2.conv1.weight\", \"body.7.rdb2.conv1.bias\", \"body.7.rdb2.conv2.weight\", \"body.7.rdb2.conv2.bias\", \"body.7.rdb2.conv3.weight\", \"body.7.rdb2.conv3.bias\", \"body.7.rdb2.conv4.weight\", \"body.7.rdb2.conv4.bias\", \"body.7.rdb2.conv5.weight\", \"body.7.rdb2.conv5.bias\", \"body.7.rdb3.conv1.weight\", \"body.7.rdb3.conv1.bias\", \"body.7.rdb3.conv2.weight\", \"body.7.rdb3.conv2.bias\", \"body.7.rdb3.conv3.weight\", \"body.7.rdb3.conv3.bias\", \"body.7.rdb3.conv4.weight\", \"body.7.rdb3.conv4.bias\", \"body.7.rdb3.conv5.weight\", \"body.7.rdb3.conv5.bias\", \"body.8.rdb1.conv1.weight\", \"body.8.rdb1.conv1.bias\", \"body.8.rdb1.conv2.weight\", \"body.8.rdb1.conv2.bias\", \"body.8.rdb1.conv3.weight\", \"body.8.rdb1.conv3.bias\", \"body.8.rdb1.conv4.weight\", \"body.8.rdb1.conv4.bias\", \"body.8.rdb1.conv5.weight\", \"body.8.rdb1.conv5.bias\", \"body.8.rdb2.conv1.weight\", \"body.8.rdb2.conv1.bias\", \"body.8.rdb2.conv2.weight\", \"body.8.rdb2.conv2.bias\", \"body.8.rdb2.conv3.weight\", \"body.8.rdb2.conv3.bias\", \"body.8.rdb2.conv4.weight\", \"body.8.rdb2.conv4.bias\", \"body.8.rdb2.conv5.weight\", \"body.8.rdb2.conv5.bias\", \"body.8.rdb3.conv1.weight\", \"body.8.rdb3.conv1.bias\", \"body.8.rdb3.conv2.weight\", \"body.8.rdb3.conv2.bias\", \"body.8.rdb3.conv3.weight\", \"body.8.rdb3.conv3.bias\", \"body.8.rdb3.conv4.weight\", \"body.8.rdb3.conv4.bias\", \"body.8.rdb3.conv5.weight\", \"body.8.rdb3.conv5.bias\", \"body.9.rdb1.conv1.weight\", \"body.9.rdb1.conv1.bias\", \"body.9.rdb1.conv2.weight\", \"body.9.rdb1.conv2.bias\", \"body.9.rdb1.conv3.weight\", \"body.9.rdb1.conv3.bias\", \"body.9.rdb1.conv4.weight\", \"body.9.rdb1.conv4.bias\", \"body.9.rdb1.conv5.weight\", \"body.9.rdb1.conv5.bias\", \"body.9.rdb2.conv1.weight\", \"body.9.rdb2.conv1.bias\", \"body.9.rdb2.conv2.weight\", \"body.9.rdb2.conv2.bias\", \"body.9.rdb2.conv3.weight\", \"body.9.rdb2.conv3.bias\", \"body.9.rdb2.conv4.weight\", \"body.9.rdb2.conv4.bias\", \"body.9.rdb2.conv5.weight\", \"body.9.rdb2.conv5.bias\", \"body.9.rdb3.conv1.weight\", \"body.9.rdb3.conv1.bias\", \"body.9.rdb3.conv2.weight\", \"body.9.rdb3.conv2.bias\", \"body.9.rdb3.conv3.weight\", \"body.9.rdb3.conv3.bias\", \"body.9.rdb3.conv4.weight\", \"body.9.rdb3.conv4.bias\", \"body.9.rdb3.conv5.weight\", \"body.9.rdb3.conv5.bias\", \"body.10.rdb1.conv1.weight\", \"body.10.rdb1.conv1.bias\", \"body.10.rdb1.conv2.weight\", \"body.10.rdb1.conv2.bias\", \"body.10.rdb1.conv3.weight\", \"body.10.rdb1.conv3.bias\", \"body.10.rdb1.conv4.weight\", \"body.10.rdb1.conv4.bias\", \"body.10.rdb1.conv5.weight\", \"body.10.rdb1.conv5.bias\", \"body.10.rdb2.conv1.weight\", \"body.10.rdb2.conv1.bias\", \"body.10.rdb2.conv2.weight\", \"body.10.rdb2.conv2.bias\", \"body.10.rdb2.conv3.weight\", \"body.10.rdb2.conv3.bias\", \"body.10.rdb2.conv4.weight\", \"body.10.rdb2.conv4.bias\", \"body.10.rdb2.conv5.weight\", \"body.10.rdb2.conv5.bias\", \"body.10.rdb3.conv1.weight\", \"body.10.rdb3.conv1.bias\", \"body.10.rdb3.conv2.weight\", \"body.10.rdb3.conv2.bias\", \"body.10.rdb3.conv3.weight\", \"body.10.rdb3.conv3.bias\", \"body.10.rdb3.conv4.weight\", \"body.10.rdb3.conv4.bias\", \"body.10.rdb3.conv5.weight\", \"body.10.rdb3.conv5.bias\", \"body.11.rdb1.conv1.weight\", \"body.11.rdb1.conv1.bias\", \"body.11.rdb1.conv2.weight\", \"body.11.rdb1.conv2.bias\", \"body.11.rdb1.conv3.weight\", \"body.11.rdb1.conv3.bias\", \"body.11.rdb1.conv4.weight\", \"body.11.rdb1.conv4.bias\", \"body.11.rdb1.conv5.weight\", \"body.11.rdb1.conv5.bias\", \"body.11.rdb2.conv1.weight\", \"body.11.rdb2.conv1.bias\", \"body.11.rdb2.conv2.weight\", \"body.11.rdb2.conv2.bias\", \"body.11.rdb2.conv3.weight\", \"body.11.rdb2.conv3.bias\", \"body.11.rdb2.conv4.weight\", \"body.11.rdb2.conv4.bias\", \"body.11.rdb2.conv5.weight\", \"body.11.rdb2.conv5.bias\", \"body.11.rdb3.conv1.weight\", \"body.11.rdb3.conv1.bias\", \"body.11.rdb3.conv2.weight\", \"body.11.rdb3.conv2.bias\", \"body.11.rdb3.conv3.weight\", \"body.11.rdb3.conv3.bias\", \"body.11.rdb3.conv4.weight\", \"body.11.rdb3.conv4.bias\", \"body.11.rdb3.conv5.weight\", \"body.11.rdb3.conv5.bias\", \"body.12.rdb1.conv1.weight\", \"body.12.rdb1.conv1.bias\", \"body.12.rdb1.conv2.weight\", \"body.12.rdb1.conv2.bias\", \"body.12.rdb1.conv3.weight\", \"body.12.rdb1.conv3.bias\", \"body.12.rdb1.conv4.weight\", \"body.12.rdb1.conv4.bias\", \"body.12.rdb1.conv5.weight\", \"body.12.rdb1.conv5.bias\", \"body.12.rdb2.conv1.weight\", \"body.12.rdb2.conv1.bias\", \"body.12.rdb2.conv2.weight\", \"body.12.rdb2.conv2.bias\", \"body.12.rdb2.conv3.weight\", \"body.12.rdb2.conv3.bias\", \"body.12.rdb2.conv4.weight\", \"body.12.rdb2.conv4.bias\", \"body.12.rdb2.conv5.weight\", \"body.12.rdb2.conv5.bias\", \"body.12.rdb3.conv1.weight\", \"body.12.rdb3.conv1.bias\", \"body.12.rdb3.conv2.weight\", \"body.12.rdb3.conv2.bias\", \"body.12.rdb3.conv3.weight\", \"body.12.rdb3.conv3.bias\", \"body.12.rdb3.conv4.weight\", \"body.12.rdb3.conv4.bias\", \"body.12.rdb3.conv5.weight\", \"body.12.rdb3.conv5.bias\", \"body.13.rdb1.conv1.weight\", \"body.13.rdb1.conv1.bias\", \"body.13.rdb1.conv2.weight\", \"body.13.rdb1.conv2.bias\", \"body.13.rdb1.conv3.weight\", \"body.13.rdb1.conv3.bias\", \"body.13.rdb1.conv4.weight\", \"body.13.rdb1.conv4.bias\", \"body.13.rdb1.conv5.weight\", \"body.13.rdb1.conv5.bias\", \"body.13.rdb2.conv1.weight\", \"body.13.rdb2.conv1.bias\", \"body.13.rdb2.conv2.weight\", \"body.13.rdb2.conv2.bias\", \"body.13.rdb2.conv3.weight\", \"body.13.rdb2.conv3.bias\", \"body.13.rdb2.conv4.weight\", \"body.13.rdb2.conv4.bias\", \"body.13.rdb2.conv5.weight\", \"body.13.rdb2.conv5.bias\", \"body.13.rdb3.conv1.weight\", \"body.13.rdb3.conv1.bias\", \"body.13.rdb3.conv2.weight\", \"body.13.rdb3.conv2.bias\", \"body.13.rdb3.conv3.weight\", \"body.13.rdb3.conv3.bias\", \"body.13.rdb3.conv4.weight\", \"body.13.rdb3.conv4.bias\", \"body.13.rdb3.conv5.weight\", \"body.13.rdb3.conv5.bias\", \"body.14.rdb1.conv1.weight\", \"body.14.rdb1.conv1.bias\", \"body.14.rdb1.conv2.weight\", \"body.14.rdb1.conv2.bias\", \"body.14.rdb1.conv3.weight\", \"body.14.rdb1.conv3.bias\", \"body.14.rdb1.conv4.weight\", \"body.14.rdb1.conv4.bias\", \"body.14.rdb1.conv5.weight\", \"body.14.rdb1.conv5.bias\", \"body.14.rdb2.conv1.weight\", \"body.14.rdb2.conv1.bias\", \"body.14.rdb2.conv2.weight\", \"body.14.rdb2.conv2.bias\", \"body.14.rdb2.conv3.weight\", \"body.14.rdb2.conv3.bias\", \"body.14.rdb2.conv4.weight\", \"body.14.rdb2.conv4.bias\", \"body.14.rdb2.conv5.weight\", \"body.14.rdb2.conv5.bias\", \"body.14.rdb3.conv1.weight\", \"body.14.rdb3.conv1.bias\", \"body.14.rdb3.conv2.weight\", \"body.14.rdb3.conv2.bias\", \"body.14.rdb3.conv3.weight\", \"body.14.rdb3.conv3.bias\", \"body.14.rdb3.conv4.weight\", \"body.14.rdb3.conv4.bias\", \"body.14.rdb3.conv5.weight\", \"body.14.rdb3.conv5.bias\", \"body.15.rdb1.conv1.weight\", \"body.15.rdb1.conv1.bias\", \"body.15.rdb1.conv2.weight\", \"body.15.rdb1.conv2.bias\", \"body.15.rdb1.conv3.weight\", \"body.15.rdb1.conv3.bias\", \"body.15.rdb1.conv4.weight\", \"body.15.rdb1.conv4.bias\", \"body.15.rdb1.conv5.weight\", \"body.15.rdb1.conv5.bias\", \"body.15.rdb2.conv1.weight\", \"body.15.rdb2.conv1.bias\", \"body.15.rdb2.conv2.weight\", \"body.15.rdb2.conv2.bias\", \"body.15.rdb2.conv3.weight\", \"body.15.rdb2.conv3.bias\", \"body.15.rdb2.conv4.weight\", \"body.15.rdb2.conv4.bias\", \"body.15.rdb2.conv5.weight\", \"body.15.rdb2.conv5.bias\", \"body.15.rdb3.conv1.weight\", \"body.15.rdb3.conv1.bias\", \"body.15.rdb3.conv2.weight\", \"body.15.rdb3.conv2.bias\", \"body.15.rdb3.conv3.weight\", \"body.15.rdb3.conv3.bias\", \"body.15.rdb3.conv4.weight\", \"body.15.rdb3.conv4.bias\", \"body.15.rdb3.conv5.weight\", \"body.15.rdb3.conv5.bias\", \"body.16.rdb1.conv1.weight\", \"body.16.rdb1.conv1.bias\", \"body.16.rdb1.conv2.weight\", \"body.16.rdb1.conv2.bias\", \"body.16.rdb1.conv3.weight\", \"body.16.rdb1.conv3.bias\", \"body.16.rdb1.conv4.weight\", \"body.16.rdb1.conv4.bias\", \"body.16.rdb1.conv5.weight\", \"body.16.rdb1.conv5.bias\", \"body.16.rdb2.conv1.weight\", \"body.16.rdb2.conv1.bias\", \"body.16.rdb2.conv2.weight\", \"body.16.rdb2.conv2.bias\", \"body.16.rdb2.conv3.weight\", \"body.16.rdb2.conv3.bias\", \"body.16.rdb2.conv4.weight\", \"body.16.rdb2.conv4.bias\", \"body.16.rdb2.conv5.weight\", \"body.16.rdb2.conv5.bias\", \"body.16.rdb3.conv1.weight\", \"body.16.rdb3.conv1.bias\", \"body.16.rdb3.conv2.weight\", \"body.16.rdb3.conv2.bias\", \"body.16.rdb3.conv3.weight\", \"body.16.rdb3.conv3.bias\", \"body.16.rdb3.conv4.weight\", \"body.16.rdb3.conv4.bias\", \"body.16.rdb3.conv5.weight\", \"body.16.rdb3.conv5.bias\", \"body.17.rdb1.conv1.weight\", \"body.17.rdb1.conv1.bias\", \"body.17.rdb1.conv2.weight\", \"body.17.rdb1.conv2.bias\", \"body.17.rdb1.conv3.weight\", \"body.17.rdb1.conv3.bias\", \"body.17.rdb1.conv4.weight\", \"body.17.rdb1.conv4.bias\", \"body.17.rdb1.conv5.weight\", \"body.17.rdb1.conv5.bias\", \"body.17.rdb2.conv1.weight\", \"body.17.rdb2.conv1.bias\", \"body.17.rdb2.conv2.weight\", \"body.17.rdb2.conv2.bias\", \"body.17.rdb2.conv3.weight\", \"body.17.rdb2.conv3.bias\", \"body.17.rdb2.conv4.weight\", \"body.17.rdb2.conv4.bias\", \"body.17.rdb2.conv5.weight\", \"body.17.rdb2.conv5.bias\", \"body.17.rdb3.conv1.weight\", \"body.17.rdb3.conv1.bias\", \"body.17.rdb3.conv2.weight\", \"body.17.rdb3.conv2.bias\", \"body.17.rdb3.conv3.weight\", \"body.17.rdb3.conv3.bias\", \"body.17.rdb3.conv4.weight\", \"body.17.rdb3.conv4.bias\", \"body.17.rdb3.conv5.weight\", \"body.17.rdb3.conv5.bias\", \"body.18.rdb1.conv1.weight\", \"body.18.rdb1.conv1.bias\", \"body.18.rdb1.conv2.weight\", \"body.18.rdb1.conv2.bias\", \"body.18.rdb1.conv3.weight\", \"body.18.rdb1.conv3.bias\", \"body.18.rdb1.conv4.weight\", \"body.18.rdb1.conv4.bias\", \"body.18.rdb1.conv5.weight\", \"body.18.rdb1.conv5.bias\", \"body.18.rdb2.conv1.weight\", \"body.18.rdb2.conv1.bias\", \"body.18.rdb2.conv2.weight\", \"body.18.rdb2.conv2.bias\", \"body.18.rdb2.conv3.weight\", \"body.18.rdb2.conv3.bias\", \"body.18.rdb2.conv4.weight\", \"body.18.rdb2.conv4.bias\", \"body.18.rdb2.conv5.weight\", \"body.18.rdb2.conv5.bias\", \"body.18.rdb3.conv1.weight\", \"body.18.rdb3.conv1.bias\", \"body.18.rdb3.conv2.weight\", \"body.18.rdb3.conv2.bias\", \"body.18.rdb3.conv3.weight\", \"body.18.rdb3.conv3.bias\", \"body.18.rdb3.conv4.weight\", \"body.18.rdb3.conv4.bias\", \"body.18.rdb3.conv5.weight\", \"body.18.rdb3.conv5.bias\", \"body.19.rdb1.conv1.weight\", \"body.19.rdb1.conv1.bias\", \"body.19.rdb1.conv2.weight\", \"body.19.rdb1.conv2.bias\", \"body.19.rdb1.conv3.weight\", \"body.19.rdb1.conv3.bias\", \"body.19.rdb1.conv4.weight\", \"body.19.rdb1.conv4.bias\", \"body.19.rdb1.conv5.weight\", \"body.19.rdb1.conv5.bias\", \"body.19.rdb2.conv1.weight\", \"body.19.rdb2.conv1.bias\", \"body.19.rdb2.conv2.weight\", \"body.19.rdb2.conv2.bias\", \"body.19.rdb2.conv3.weight\", \"body.19.rdb2.conv3.bias\", \"body.19.rdb2.conv4.weight\", \"body.19.rdb2.conv4.bias\", \"body.19.rdb2.conv5.weight\", \"body.19.rdb2.conv5.bias\", \"body.19.rdb3.conv1.weight\", \"body.19.rdb3.conv1.bias\", \"body.19.rdb3.conv2.weight\", \"body.19.rdb3.conv2.bias\", \"body.19.rdb3.conv3.weight\", \"body.19.rdb3.conv3.bias\", \"body.19.rdb3.conv4.weight\", \"body.19.rdb3.conv4.bias\", \"body.19.rdb3.conv5.weight\", \"body.19.rdb3.conv5.bias\", \"body.20.rdb1.conv1.weight\", \"body.20.rdb1.conv1.bias\", \"body.20.rdb1.conv2.weight\", \"body.20.rdb1.conv2.bias\", \"body.20.rdb1.conv3.weight\", \"body.20.rdb1.conv3.bias\", \"body.20.rdb1.conv4.weight\", \"body.20.rdb1.conv4.bias\", \"body.20.rdb1.conv5.weight\", \"body.20.rdb1.conv5.bias\", \"body.20.rdb2.conv1.weight\", \"body.20.rdb2.conv1.bias\", \"body.20.rdb2.conv2.weight\", \"body.20.rdb2.conv2.bias\", \"body.20.rdb2.conv3.weight\", \"body.20.rdb2.conv3.bias\", \"body.20.rdb2.conv4.weight\", \"body.20.rdb2.conv4.bias\", \"body.20.rdb2.conv5.weight\", \"body.20.rdb2.conv5.bias\", \"body.20.rdb3.conv1.weight\", \"body.20.rdb3.conv1.bias\", \"body.20.rdb3.conv2.weight\", \"body.20.rdb3.conv2.bias\", \"body.20.rdb3.conv3.weight\", \"body.20.rdb3.conv3.bias\", \"body.20.rdb3.conv4.weight\", \"body.20.rdb3.conv4.bias\", \"body.20.rdb3.conv5.weight\", \"body.20.rdb3.conv5.bias\", \"body.21.rdb1.conv1.weight\", \"body.21.rdb1.conv1.bias\", \"body.21.rdb1.conv2.weight\", \"body.21.rdb1.conv2.bias\", \"body.21.rdb1.conv3.weight\", \"body.21.rdb1.conv3.bias\", \"body.21.rdb1.conv4.weight\", \"body.21.rdb1.conv4.bias\", \"body.21.rdb1.conv5.weight\", \"body.21.rdb1.conv5.bias\", \"body.21.rdb2.conv1.weight\", \"body.21.rdb2.conv1.bias\", \"body.21.rdb2.conv2.weight\", \"body.21.rdb2.conv2.bias\", \"body.21.rdb2.conv3.weight\", \"body.21.rdb2.conv3.bias\", \"body.21.rdb2.conv4.weight\", \"body.21.rdb2.conv4.bias\", \"body.21.rdb2.conv5.weight\", \"body.21.rdb2.conv5.bias\", \"body.21.rdb3.conv1.weight\", \"body.21.rdb3.conv1.bias\", \"body.21.rdb3.conv2.weight\", \"body.21.rdb3.conv2.bias\", \"body.21.rdb3.conv3.weight\", \"body.21.rdb3.conv3.bias\", \"body.21.rdb3.conv4.weight\", \"body.21.rdb3.conv4.bias\", \"body.21.rdb3.conv5.weight\", \"body.21.rdb3.conv5.bias\", \"body.22.rdb1.conv1.weight\", \"body.22.rdb1.conv1.bias\", \"body.22.rdb1.conv2.weight\", \"body.22.rdb1.conv2.bias\", \"body.22.rdb1.conv3.weight\", \"body.22.rdb1.conv3.bias\", \"body.22.rdb1.conv4.weight\", \"body.22.rdb1.conv4.bias\", \"body.22.rdb1.conv5.weight\", \"body.22.rdb1.conv5.bias\", \"body.22.rdb2.conv1.weight\", \"body.22.rdb2.conv1.bias\", \"body.22.rdb2.conv2.weight\", \"body.22.rdb2.conv2.bias\", \"body.22.rdb2.conv3.weight\", \"body.22.rdb2.conv3.bias\", \"body.22.rdb2.conv4.weight\", \"body.22.rdb2.conv4.bias\", \"body.22.rdb2.conv5.weight\", \"body.22.rdb2.conv5.bias\", \"body.22.rdb3.conv1.weight\", \"body.22.rdb3.conv1.bias\", \"body.22.rdb3.conv2.weight\", \"body.22.rdb3.conv2.bias\", \"body.22.rdb3.conv3.weight\", \"body.22.rdb3.conv3.bias\", \"body.22.rdb3.conv4.weight\", \"body.22.rdb3.conv4.bias\", \"body.22.rdb3.conv5.weight\", \"body.22.rdb3.conv5.bias\", \"conv_body.weight\", \"conv_body.bias\", \"conv_up1.weight\", \"conv_up1.bias\", \"conv_up2.weight\", \"conv_up2.bias\", \"conv_hr.weight\", \"conv_hr.bias\", \"conv_last.weight\", \"conv_last.bias\". \n\tUnexpected key(s) in state_dict: \"params_ema\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 69\u001b[0m\n\u001b[1;32m     66\u001b[0m     final_image\u001b[38;5;241m.\u001b[39msave(output_path)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Ejemplo de uso\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m \u001b[43mprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCelebA/celebA/img_align_celeba/img_align_celeba/125479.jpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mESRGAN_output_image.jpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRealESRGAN_x4plus.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 58\u001b[0m, in \u001b[0;36mprocess_image\u001b[0;34m(input_path, output_path, model_path)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Cargar el modelo de super-resolución ESRGAN\u001b[39;00m\n\u001b[1;32m     57\u001b[0m model \u001b[38;5;241m=\u001b[39m RRDBNet(num_in_ch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, num_out_ch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, num_feat\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, num_block\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m23\u001b[39m, num_grow_ch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m---> 58\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     60\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/GAN/lib/python3.8/site-packages/torch/nn/modules/module.py:1671\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1666\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   1667\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1668\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1670\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1671\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1672\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1673\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for RRDBNet:\n\tMissing key(s) in state_dict: \"conv_first.weight\", \"conv_first.bias\", \"body.0.rdb1.conv1.weight\", \"body.0.rdb1.conv1.bias\", \"body.0.rdb1.conv2.weight\", \"body.0.rdb1.conv2.bias\", \"body.0.rdb1.conv3.weight\", \"body.0.rdb1.conv3.bias\", \"body.0.rdb1.conv4.weight\", \"body.0.rdb1.conv4.bias\", \"body.0.rdb1.conv5.weight\", \"body.0.rdb1.conv5.bias\", \"body.0.rdb2.conv1.weight\", \"body.0.rdb2.conv1.bias\", \"body.0.rdb2.conv2.weight\", \"body.0.rdb2.conv2.bias\", \"body.0.rdb2.conv3.weight\", \"body.0.rdb2.conv3.bias\", \"body.0.rdb2.conv4.weight\", \"body.0.rdb2.conv4.bias\", \"body.0.rdb2.conv5.weight\", \"body.0.rdb2.conv5.bias\", \"body.0.rdb3.conv1.weight\", \"body.0.rdb3.conv1.bias\", \"body.0.rdb3.conv2.weight\", \"body.0.rdb3.conv2.bias\", \"body.0.rdb3.conv3.weight\", \"body.0.rdb3.conv3.bias\", \"body.0.rdb3.conv4.weight\", \"body.0.rdb3.conv4.bias\", \"body.0.rdb3.conv5.weight\", \"body.0.rdb3.conv5.bias\", \"body.1.rdb1.conv1.weight\", \"body.1.rdb1.conv1.bias\", \"body.1.rdb1.conv2.weight\", \"body.1.rdb1.conv2.bias\", \"body.1.rdb1.conv3.weight\", \"body.1.rdb1.conv3.bias\", \"body.1.rdb1.conv4.weight\", \"body.1.rdb1.conv4.bias\", \"body.1.rdb1.conv5.weight\", \"body.1.rdb1.conv5.bias\", \"body.1.rdb2.conv1.weight\", \"body.1.rdb2.conv1.bias\", \"body.1.rdb2.conv2.weight\", \"body.1.rdb2.conv2.bias\", \"body.1.rdb2.conv3.weight\", \"body.1.rdb2.conv3.bias\", \"body.1.rdb2.conv4.weight\", \"body.1.rdb2.conv4.bias\", \"body.1.rdb2.conv5.weight\", \"body.1.rdb2.conv5.bias\", \"body.1.rdb3.conv1.weight\", \"body.1.rdb3.conv1.bias\", \"body.1.rdb3.conv2.weight\", \"body.1.rdb3.conv2.bias\", \"body.1.rdb3.conv3.weight\", \"body.1.rdb3.conv3.bias\", \"body.1.rdb3.conv4.weight\", \"body.1.rdb3.conv4.bias\", \"body.1.rdb3.conv5.weight\", \"body.1.rdb3.conv5.bias\", \"body.2.rdb1.conv1.weight\", \"body.2.rdb1.conv1.bias\", \"body.2.rdb1.conv2.weight\", \"body.2.rdb1.conv2.bias\", \"body.2.rdb1.conv3.weight\", \"body.2.rdb1.conv3.bias\", \"body.2.rdb1.conv4.weight\", \"body.2.rdb1.conv4.bias\", \"body.2.rdb1.conv5.weight\", \"body.2.rdb1.conv5.bias\", \"body.2.rdb2.conv1.weight\", \"body.2.rdb2.conv1.bias\", \"body.2.rdb2.conv2.weight\", \"body.2.rdb2.conv2.bias\", \"body.2.rdb2.conv3.weight\", \"body.2.rdb2.conv3.bias\", \"body.2.rdb2.conv4.weight\", \"body.2.rdb2.conv4.bias\", \"body.2.rdb2.conv5.weight\", \"body.2.rdb2.conv5.bias\", \"body.2.rdb3.conv1.weight\", \"body.2.rdb3.conv1.bias\", \"body.2.rdb3.conv2.weight\", \"body.2.rdb3.conv2.bias\", \"body.2.rdb3.conv3.weight\", \"body.2.rdb3.conv3.bias\", \"body.2.rdb3.conv4.weight\", \"body.2.rdb3.conv4.bias\", \"body.2.rdb3.conv5.weight\", \"body.2.rdb3.conv5.bias\", \"body.3.rdb1.conv1.weight\", \"body.3.rdb1.conv1.bias\", \"body.3.rdb1.conv2.weight\", \"body.3.rdb1.conv2.bias\", \"body.3.rdb1.conv3.weight\", \"body.3.rdb1.conv3.bias\", \"body.3.rdb1.conv4.weight\", \"body.3.rdb1.conv4.bias\", \"body.3.rdb1.conv5.weight\", \"body.3.rdb1.conv5.bias\", \"body.3.rdb2.conv1.weight\", \"body.3.rdb2.conv1.bias\", \"body.3.rdb2.conv2.weight\", \"body.3.rdb2.conv2.bias\", \"body.3.rdb2.conv3.weight\", \"body.3.rdb2.conv3.bias\", \"body.3.rdb2.conv4.weight\", \"body.3.rdb2.conv4.bias\", \"body.3.rdb2.conv5.weight\", \"body.3.rdb2.conv5.bias\", \"body.3.rdb3.conv1.weight\", \"body.3.rdb3.conv1.bias\", \"body.3.rdb3.conv2.weight\", \"body.3.rdb3.conv2.bias\", \"body.3.rdb3.conv3.weight\", \"body.3.rdb3.conv3.bias\", \"body.3.rdb3.conv4.weight\", \"body.3.rdb3.conv4.bias\", \"body.3.rdb3.conv5.weight\", \"body.3.rdb3.conv5.bias\", \"body.4.rdb1.conv1.weight\", \"body.4.rdb1.conv1.bias\", \"body.4.rdb1.conv2.weight\", \"body.4.rdb1.conv2.bias\", \"body.4.rdb1.conv3.weight\", \"body.4.rdb1.conv3.bias\", \"body.4.rdb1.conv4.weight\", \"body.4.rdb1.conv4.bias\", \"body.4.rdb1.conv5.weight\", \"body.4.rdb1.conv5.bias\", \"body.4.rdb2.conv1.weight\", \"body.4.rdb2.conv1.bias\", \"body.4.rdb2.conv2.weight\", \"body.4.rdb2.conv2.bias\", \"body.4.rdb2.conv3.weight\", \"body.4.rdb2.conv3.bias\", \"body.4.rdb2.conv4.weight\", \"body.4.rdb2.conv4.bias\", \"body.4.rdb2.conv5.weight\", \"body.4.rdb2.conv5.bias\", \"body.4.rdb3.conv1.weight\", \"body.4.rdb3.conv1.bias\", \"body.4.rdb3.conv2.weight\", \"body.4.rdb3.conv2.bias\", \"body.4.rdb3.conv3.weight\", \"body.4.rdb3.conv3.bias\", \"body.4.rdb3.conv4.weight\", \"body.4.rdb3.conv4.bias\", \"body.4.rdb3.conv5.weight\", \"body.4.rdb3.conv5.bias\", \"body.5.rdb1.conv1.weight\", \"body.5.rdb1.conv1.bias\", \"body.5.rdb1.conv2.weight\", \"body.5.rdb1.conv2.bias\", \"body.5.rdb1.conv3.weight\", \"body.5.rdb1.conv3.bias\", \"body.5.rdb1.conv4.weight\", \"body.5.rdb1.conv4.bias\", \"body.5.rdb1.conv5.weight\", \"body.5.rdb1.conv5.bias\", \"body.5.rdb2.conv1.weight\", \"body.5.rdb2.conv1.bias\", \"body.5.rdb2.conv2.weight\", \"body.5.rdb2.conv2.bias\", \"body.5.rdb2.conv3.weight\", \"body.5.rdb2.conv3.bias\", \"body.5.rdb2.conv4.weight\", \"body.5.rdb2.conv4.bias\", \"body.5.rdb2.conv5.weight\", \"body.5.rdb2.conv5.bias\", \"body.5.rdb3.conv1.weight\", \"body.5.rdb3.conv1.bias\", \"body.5.rdb3.conv2.weight\", \"body.5.rdb3.conv2.bias\", \"body.5.rdb3.conv3.weight\", \"body.5.rdb3.conv3.bias\", \"body.5.rdb3.conv4.weight\", \"body.5.rdb3.conv4.bias\", \"body.5.rdb3.conv5.weight\", \"body.5.rdb3.conv5.bias\", \"body.6.rdb1.conv1.weight\", \"body.6.rdb1.conv1.bias\", \"body.6.rdb1.conv2.weight\", \"body.6.rdb1.conv2.bias\", \"body.6.rdb1.conv3.weight\", \"body.6.rdb1.conv3.bias\", \"body.6.rdb1.conv4.weight\", \"body.6.rdb1.conv4.bias\", \"body.6.rdb1.conv5.weight\", \"body.6.rdb1.conv5.bias\", \"body.6.rdb2.conv1.weight\", \"body.6.rdb2.conv1.bias\", \"body.6.rdb2.conv2.weight\", \"body.6.rdb2.conv2.bias\", \"body.6.rdb2.conv3.weight\", \"body.6.rdb2.conv3.bias\", \"body.6.rdb2.conv4.weight\", \"body.6.rdb2.conv4.bias\", \"body.6.rdb2.conv5.weight\", \"body.6.rdb2.conv5.bias\", \"body.6.rdb3.conv1.weight\", \"body.6.rdb3.conv1.bias\", \"body.6.rdb3.conv2.weight\", \"body.6.rdb3.conv2.bias\", \"body.6.rdb3.conv3.weight\", \"body.6.rdb3.conv3.bias\", \"body.6.rdb3.conv4.weight\", \"body.6.rdb3.conv4.bias\", \"body.6.rdb3.conv5.weight\", \"body.6.rdb3.conv5.bias\", \"body.7.rdb1.conv1.weight\", \"body.7.rdb1.conv1.bias\", \"body.7.rdb1.conv2.weight\", \"body.7.rdb1.conv2.bias\", \"body.7.rdb1.conv3.weight\", \"body.7.rdb1.conv3.bias\", \"body.7.rdb1.conv4.weight\", \"body.7.rdb1.conv4.bias\", \"body.7.rdb1.conv5.weight\", \"body.7.rdb1.conv5.bias\", \"body.7.rdb2.conv1.weight\", \"body.7.rdb2.conv1.bias\", \"body.7.rdb2.conv2.weight\", \"body.7.rdb2.conv2.bias\", \"body.7.rdb2.conv3.weight\", \"body.7.rdb2.conv3.bias\", \"body.7.rdb2.conv4.weight\", \"body.7.rdb2.conv4.bias\", \"body.7.rdb2.conv5.weight\", \"body.7.rdb2.conv5.bias\", \"body.7.rdb3.conv1.weight\", \"body.7.rdb3.conv1.bias\", \"body.7.rdb3.conv2.weight\", \"body.7.rdb3.conv2.bias\", \"body.7.rdb3.conv3.weight\", \"body.7.rdb3.conv3.bias\", \"body.7.rdb3.conv4.weight\", \"body.7.rdb3.conv4.bias\", \"body.7.rdb3.conv5.weight\", \"body.7.rdb3.conv5.bias\", \"body.8.rdb1.conv1.weight\", \"body.8.rdb1.conv1.bias\", \"body.8.rdb1.conv2.weight\", \"body.8.rdb1.conv2.bias\", \"body.8.rdb1.conv3.weight\", \"body.8.rdb1.conv3.bias\", \"body.8.rdb1.conv4.weight\", \"body.8.rdb1.conv4.bias\", \"body.8.rdb1.conv5.weight\", \"body.8.rdb1.conv5.bias\", \"body.8.rdb2.conv1.weight\", \"body.8.rdb2.conv1.bias\", \"body.8.rdb2.conv2.weight\", \"body.8.rdb2.conv2.bias\", \"body.8.rdb2.conv3.weight\", \"body.8.rdb2.conv3.bias\", \"body.8.rdb2.conv4.weight\", \"body.8.rdb2.conv4.bias\", \"body.8.rdb2.conv5.weight\", \"body.8.rdb2.conv5.bias\", \"body.8.rdb3.conv1.weight\", \"body.8.rdb3.conv1.bias\", \"body.8.rdb3.conv2.weight\", \"body.8.rdb3.conv2.bias\", \"body.8.rdb3.conv3.weight\", \"body.8.rdb3.conv3.bias\", \"body.8.rdb3.conv4.weight\", \"body.8.rdb3.conv4.bias\", \"body.8.rdb3.conv5.weight\", \"body.8.rdb3.conv5.bias\", \"body.9.rdb1.conv1.weight\", \"body.9.rdb1.conv1.bias\", \"body.9.rdb1.conv2.weight\", \"body.9.rdb1.conv2.bias\", \"body.9.rdb1.conv3.weight\", \"body.9.rdb1.conv3.bias\", \"body.9.rdb1.conv4.weight\", \"body.9.rdb1.conv4.bias\", \"body.9.rdb1.conv5.weight\", \"body.9.rdb1.conv5.bias\", \"body.9.rdb2.conv1.weight\", \"body.9.rdb2.conv1.bias\", \"body.9.rdb2.conv2.weight\", \"body.9.rdb2.conv2.bias\", \"body.9.rdb2.conv3.weight\", \"body.9.rdb2.conv3.bias\", \"body.9.rdb2.conv4.weight\", \"body.9.rdb2.conv4.bias\", \"body.9.rdb2.conv5.weight\", \"body.9.rdb2.conv5.bias\", \"body.9.rdb3.conv1.weight\", \"body.9.rdb3.conv1.bias\", \"body.9.rdb3.conv2.weight\", \"body.9.rdb3.conv2.bias\", \"body.9.rdb3.conv3.weight\", \"body.9.rdb3.conv3.bias\", \"body.9.rdb3.conv4.weight\", \"body.9.rdb3.conv4.bias\", \"body.9.rdb3.conv5.weight\", \"body.9.rdb3.conv5.bias\", \"body.10.rdb1.conv1.weight\", \"body.10.rdb1.conv1.bias\", \"body.10.rdb1.conv2.weight\", \"body.10.rdb1.conv2.bias\", \"body.10.rdb1.conv3.weight\", \"body.10.rdb1.conv3.bias\", \"body.10.rdb1.conv4.weight\", \"body.10.rdb1.conv4.bias\", \"body.10.rdb1.conv5.weight\", \"body.10.rdb1.conv5.bias\", \"body.10.rdb2.conv1.weight\", \"body.10.rdb2.conv1.bias\", \"body.10.rdb2.conv2.weight\", \"body.10.rdb2.conv2.bias\", \"body.10.rdb2.conv3.weight\", \"body.10.rdb2.conv3.bias\", \"body.10.rdb2.conv4.weight\", \"body.10.rdb2.conv4.bias\", \"body.10.rdb2.conv5.weight\", \"body.10.rdb2.conv5.bias\", \"body.10.rdb3.conv1.weight\", \"body.10.rdb3.conv1.bias\", \"body.10.rdb3.conv2.weight\", \"body.10.rdb3.conv2.bias\", \"body.10.rdb3.conv3.weight\", \"body.10.rdb3.conv3.bias\", \"body.10.rdb3.conv4.weight\", \"body.10.rdb3.conv4.bias\", \"body.10.rdb3.conv5.weight\", \"body.10.rdb3.conv5.bias\", \"body.11.rdb1.conv1.weight\", \"body.11.rdb1.conv1.bias\", \"body.11.rdb1.conv2.weight\", \"body.11.rdb1.conv2.bias\", \"body.11.rdb1.conv3.weight\", \"body.11.rdb1.conv3.bias\", \"body.11.rdb1.conv4.weight\", \"body.11.rdb1.conv4.bias\", \"body.11.rdb1.conv5.weight\", \"body.11.rdb1.conv5.bias\", \"body.11.rdb2.conv1.weight\", \"body.11.rdb2.conv1.bias\", \"body.11.rdb2.conv2.weight\", \"body.11.rdb2.conv2.bias\", \"body.11.rdb2.conv3.weight\", \"body.11.rdb2.conv3.bias\", \"body.11.rdb2.conv4.weight\", \"body.11.rdb2.conv4.bias\", \"body.11.rdb2.conv5.weight\", \"body.11.rdb2.conv5.bias\", \"body.11.rdb3.conv1.weight\", \"body.11.rdb3.conv1.bias\", \"body.11.rdb3.conv2.weight\", \"body.11.rdb3.conv2.bias\", \"body.11.rdb3.conv3.weight\", \"body.11.rdb3.conv3.bias\", \"body.11.rdb3.conv4.weight\", \"body.11.rdb3.conv4.bias\", \"body.11.rdb3.conv5.weight\", \"body.11.rdb3.conv5.bias\", \"body.12.rdb1.conv1.weight\", \"body.12.rdb1.conv1.bias\", \"body.12.rdb1.conv2.weight\", \"body.12.rdb1.conv2.bias\", \"body.12.rdb1.conv3.weight\", \"body.12.rdb1.conv3.bias\", \"body.12.rdb1.conv4.weight\", \"body.12.rdb1.conv4.bias\", \"body.12.rdb1.conv5.weight\", \"body.12.rdb1.conv5.bias\", \"body.12.rdb2.conv1.weight\", \"body.12.rdb2.conv1.bias\", \"body.12.rdb2.conv2.weight\", \"body.12.rdb2.conv2.bias\", \"body.12.rdb2.conv3.weight\", \"body.12.rdb2.conv3.bias\", \"body.12.rdb2.conv4.weight\", \"body.12.rdb2.conv4.bias\", \"body.12.rdb2.conv5.weight\", \"body.12.rdb2.conv5.bias\", \"body.12.rdb3.conv1.weight\", \"body.12.rdb3.conv1.bias\", \"body.12.rdb3.conv2.weight\", \"body.12.rdb3.conv2.bias\", \"body.12.rdb3.conv3.weight\", \"body.12.rdb3.conv3.bias\", \"body.12.rdb3.conv4.weight\", \"body.12.rdb3.conv4.bias\", \"body.12.rdb3.conv5.weight\", \"body.12.rdb3.conv5.bias\", \"body.13.rdb1.conv1.weight\", \"body.13.rdb1.conv1.bias\", \"body.13.rdb1.conv2.weight\", \"body.13.rdb1.conv2.bias\", \"body.13.rdb1.conv3.weight\", \"body.13.rdb1.conv3.bias\", \"body.13.rdb1.conv4.weight\", \"body.13.rdb1.conv4.bias\", \"body.13.rdb1.conv5.weight\", \"body.13.rdb1.conv5.bias\", \"body.13.rdb2.conv1.weight\", \"body.13.rdb2.conv1.bias\", \"body.13.rdb2.conv2.weight\", \"body.13.rdb2.conv2.bias\", \"body.13.rdb2.conv3.weight\", \"body.13.rdb2.conv3.bias\", \"body.13.rdb2.conv4.weight\", \"body.13.rdb2.conv4.bias\", \"body.13.rdb2.conv5.weight\", \"body.13.rdb2.conv5.bias\", \"body.13.rdb3.conv1.weight\", \"body.13.rdb3.conv1.bias\", \"body.13.rdb3.conv2.weight\", \"body.13.rdb3.conv2.bias\", \"body.13.rdb3.conv3.weight\", \"body.13.rdb3.conv3.bias\", \"body.13.rdb3.conv4.weight\", \"body.13.rdb3.conv4.bias\", \"body.13.rdb3.conv5.weight\", \"body.13.rdb3.conv5.bias\", \"body.14.rdb1.conv1.weight\", \"body.14.rdb1.conv1.bias\", \"body.14.rdb1.conv2.weight\", \"body.14.rdb1.conv2.bias\", \"body.14.rdb1.conv3.weight\", \"body.14.rdb1.conv3.bias\", \"body.14.rdb1.conv4.weight\", \"body.14.rdb1.conv4.bias\", \"body.14.rdb1.conv5.weight\", \"body.14.rdb1.conv5.bias\", \"body.14.rdb2.conv1.weight\", \"body.14.rdb2.conv1.bias\", \"body.14.rdb2.conv2.weight\", \"body.14.rdb2.conv2.bias\", \"body.14.rdb2.conv3.weight\", \"body.14.rdb2.conv3.bias\", \"body.14.rdb2.conv4.weight\", \"body.14.rdb2.conv4.bias\", \"body.14.rdb2.conv5.weight\", \"body.14.rdb2.conv5.bias\", \"body.14.rdb3.conv1.weight\", \"body.14.rdb3.conv1.bias\", \"body.14.rdb3.conv2.weight\", \"body.14.rdb3.conv2.bias\", \"body.14.rdb3.conv3.weight\", \"body.14.rdb3.conv3.bias\", \"body.14.rdb3.conv4.weight\", \"body.14.rdb3.conv4.bias\", \"body.14.rdb3.conv5.weight\", \"body.14.rdb3.conv5.bias\", \"body.15.rdb1.conv1.weight\", \"body.15.rdb1.conv1.bias\", \"body.15.rdb1.conv2.weight\", \"body.15.rdb1.conv2.bias\", \"body.15.rdb1.conv3.weight\", \"body.15.rdb1.conv3.bias\", \"body.15.rdb1.conv4.weight\", \"body.15.rdb1.conv4.bias\", \"body.15.rdb1.conv5.weight\", \"body.15.rdb1.conv5.bias\", \"body.15.rdb2.conv1.weight\", \"body.15.rdb2.conv1.bias\", \"body.15.rdb2.conv2.weight\", \"body.15.rdb2.conv2.bias\", \"body.15.rdb2.conv3.weight\", \"body.15.rdb2.conv3.bias\", \"body.15.rdb2.conv4.weight\", \"body.15.rdb2.conv4.bias\", \"body.15.rdb2.conv5.weight\", \"body.15.rdb2.conv5.bias\", \"body.15.rdb3.conv1.weight\", \"body.15.rdb3.conv1.bias\", \"body.15.rdb3.conv2.weight\", \"body.15.rdb3.conv2.bias\", \"body.15.rdb3.conv3.weight\", \"body.15.rdb3.conv3.bias\", \"body.15.rdb3.conv4.weight\", \"body.15.rdb3.conv4.bias\", \"body.15.rdb3.conv5.weight\", \"body.15.rdb3.conv5.bias\", \"body.16.rdb1.conv1.weight\", \"body.16.rdb1.conv1.bias\", \"body.16.rdb1.conv2.weight\", \"body.16.rdb1.conv2.bias\", \"body.16.rdb1.conv3.weight\", \"body.16.rdb1.conv3.bias\", \"body.16.rdb1.conv4.weight\", \"body.16.rdb1.conv4.bias\", \"body.16.rdb1.conv5.weight\", \"body.16.rdb1.conv5.bias\", \"body.16.rdb2.conv1.weight\", \"body.16.rdb2.conv1.bias\", \"body.16.rdb2.conv2.weight\", \"body.16.rdb2.conv2.bias\", \"body.16.rdb2.conv3.weight\", \"body.16.rdb2.conv3.bias\", \"body.16.rdb2.conv4.weight\", \"body.16.rdb2.conv4.bias\", \"body.16.rdb2.conv5.weight\", \"body.16.rdb2.conv5.bias\", \"body.16.rdb3.conv1.weight\", \"body.16.rdb3.conv1.bias\", \"body.16.rdb3.conv2.weight\", \"body.16.rdb3.conv2.bias\", \"body.16.rdb3.conv3.weight\", \"body.16.rdb3.conv3.bias\", \"body.16.rdb3.conv4.weight\", \"body.16.rdb3.conv4.bias\", \"body.16.rdb3.conv5.weight\", \"body.16.rdb3.conv5.bias\", \"body.17.rdb1.conv1.weight\", \"body.17.rdb1.conv1.bias\", \"body.17.rdb1.conv2.weight\", \"body.17.rdb1.conv2.bias\", \"body.17.rdb1.conv3.weight\", \"body.17.rdb1.conv3.bias\", \"body.17.rdb1.conv4.weight\", \"body.17.rdb1.conv4.bias\", \"body.17.rdb1.conv5.weight\", \"body.17.rdb1.conv5.bias\", \"body.17.rdb2.conv1.weight\", \"body.17.rdb2.conv1.bias\", \"body.17.rdb2.conv2.weight\", \"body.17.rdb2.conv2.bias\", \"body.17.rdb2.conv3.weight\", \"body.17.rdb2.conv3.bias\", \"body.17.rdb2.conv4.weight\", \"body.17.rdb2.conv4.bias\", \"body.17.rdb2.conv5.weight\", \"body.17.rdb2.conv5.bias\", \"body.17.rdb3.conv1.weight\", \"body.17.rdb3.conv1.bias\", \"body.17.rdb3.conv2.weight\", \"body.17.rdb3.conv2.bias\", \"body.17.rdb3.conv3.weight\", \"body.17.rdb3.conv3.bias\", \"body.17.rdb3.conv4.weight\", \"body.17.rdb3.conv4.bias\", \"body.17.rdb3.conv5.weight\", \"body.17.rdb3.conv5.bias\", \"body.18.rdb1.conv1.weight\", \"body.18.rdb1.conv1.bias\", \"body.18.rdb1.conv2.weight\", \"body.18.rdb1.conv2.bias\", \"body.18.rdb1.conv3.weight\", \"body.18.rdb1.conv3.bias\", \"body.18.rdb1.conv4.weight\", \"body.18.rdb1.conv4.bias\", \"body.18.rdb1.conv5.weight\", \"body.18.rdb1.conv5.bias\", \"body.18.rdb2.conv1.weight\", \"body.18.rdb2.conv1.bias\", \"body.18.rdb2.conv2.weight\", \"body.18.rdb2.conv2.bias\", \"body.18.rdb2.conv3.weight\", \"body.18.rdb2.conv3.bias\", \"body.18.rdb2.conv4.weight\", \"body.18.rdb2.conv4.bias\", \"body.18.rdb2.conv5.weight\", \"body.18.rdb2.conv5.bias\", \"body.18.rdb3.conv1.weight\", \"body.18.rdb3.conv1.bias\", \"body.18.rdb3.conv2.weight\", \"body.18.rdb3.conv2.bias\", \"body.18.rdb3.conv3.weight\", \"body.18.rdb3.conv3.bias\", \"body.18.rdb3.conv4.weight\", \"body.18.rdb3.conv4.bias\", \"body.18.rdb3.conv5.weight\", \"body.18.rdb3.conv5.bias\", \"body.19.rdb1.conv1.weight\", \"body.19.rdb1.conv1.bias\", \"body.19.rdb1.conv2.weight\", \"body.19.rdb1.conv2.bias\", \"body.19.rdb1.conv3.weight\", \"body.19.rdb1.conv3.bias\", \"body.19.rdb1.conv4.weight\", \"body.19.rdb1.conv4.bias\", \"body.19.rdb1.conv5.weight\", \"body.19.rdb1.conv5.bias\", \"body.19.rdb2.conv1.weight\", \"body.19.rdb2.conv1.bias\", \"body.19.rdb2.conv2.weight\", \"body.19.rdb2.conv2.bias\", \"body.19.rdb2.conv3.weight\", \"body.19.rdb2.conv3.bias\", \"body.19.rdb2.conv4.weight\", \"body.19.rdb2.conv4.bias\", \"body.19.rdb2.conv5.weight\", \"body.19.rdb2.conv5.bias\", \"body.19.rdb3.conv1.weight\", \"body.19.rdb3.conv1.bias\", \"body.19.rdb3.conv2.weight\", \"body.19.rdb3.conv2.bias\", \"body.19.rdb3.conv3.weight\", \"body.19.rdb3.conv3.bias\", \"body.19.rdb3.conv4.weight\", \"body.19.rdb3.conv4.bias\", \"body.19.rdb3.conv5.weight\", \"body.19.rdb3.conv5.bias\", \"body.20.rdb1.conv1.weight\", \"body.20.rdb1.conv1.bias\", \"body.20.rdb1.conv2.weight\", \"body.20.rdb1.conv2.bias\", \"body.20.rdb1.conv3.weight\", \"body.20.rdb1.conv3.bias\", \"body.20.rdb1.conv4.weight\", \"body.20.rdb1.conv4.bias\", \"body.20.rdb1.conv5.weight\", \"body.20.rdb1.conv5.bias\", \"body.20.rdb2.conv1.weight\", \"body.20.rdb2.conv1.bias\", \"body.20.rdb2.conv2.weight\", \"body.20.rdb2.conv2.bias\", \"body.20.rdb2.conv3.weight\", \"body.20.rdb2.conv3.bias\", \"body.20.rdb2.conv4.weight\", \"body.20.rdb2.conv4.bias\", \"body.20.rdb2.conv5.weight\", \"body.20.rdb2.conv5.bias\", \"body.20.rdb3.conv1.weight\", \"body.20.rdb3.conv1.bias\", \"body.20.rdb3.conv2.weight\", \"body.20.rdb3.conv2.bias\", \"body.20.rdb3.conv3.weight\", \"body.20.rdb3.conv3.bias\", \"body.20.rdb3.conv4.weight\", \"body.20.rdb3.conv4.bias\", \"body.20.rdb3.conv5.weight\", \"body.20.rdb3.conv5.bias\", \"body.21.rdb1.conv1.weight\", \"body.21.rdb1.conv1.bias\", \"body.21.rdb1.conv2.weight\", \"body.21.rdb1.conv2.bias\", \"body.21.rdb1.conv3.weight\", \"body.21.rdb1.conv3.bias\", \"body.21.rdb1.conv4.weight\", \"body.21.rdb1.conv4.bias\", \"body.21.rdb1.conv5.weight\", \"body.21.rdb1.conv5.bias\", \"body.21.rdb2.conv1.weight\", \"body.21.rdb2.conv1.bias\", \"body.21.rdb2.conv2.weight\", \"body.21.rdb2.conv2.bias\", \"body.21.rdb2.conv3.weight\", \"body.21.rdb2.conv3.bias\", \"body.21.rdb2.conv4.weight\", \"body.21.rdb2.conv4.bias\", \"body.21.rdb2.conv5.weight\", \"body.21.rdb2.conv5.bias\", \"body.21.rdb3.conv1.weight\", \"body.21.rdb3.conv1.bias\", \"body.21.rdb3.conv2.weight\", \"body.21.rdb3.conv2.bias\", \"body.21.rdb3.conv3.weight\", \"body.21.rdb3.conv3.bias\", \"body.21.rdb3.conv4.weight\", \"body.21.rdb3.conv4.bias\", \"body.21.rdb3.conv5.weight\", \"body.21.rdb3.conv5.bias\", \"body.22.rdb1.conv1.weight\", \"body.22.rdb1.conv1.bias\", \"body.22.rdb1.conv2.weight\", \"body.22.rdb1.conv2.bias\", \"body.22.rdb1.conv3.weight\", \"body.22.rdb1.conv3.bias\", \"body.22.rdb1.conv4.weight\", \"body.22.rdb1.conv4.bias\", \"body.22.rdb1.conv5.weight\", \"body.22.rdb1.conv5.bias\", \"body.22.rdb2.conv1.weight\", \"body.22.rdb2.conv1.bias\", \"body.22.rdb2.conv2.weight\", \"body.22.rdb2.conv2.bias\", \"body.22.rdb2.conv3.weight\", \"body.22.rdb2.conv3.bias\", \"body.22.rdb2.conv4.weight\", \"body.22.rdb2.conv4.bias\", \"body.22.rdb2.conv5.weight\", \"body.22.rdb2.conv5.bias\", \"body.22.rdb3.conv1.weight\", \"body.22.rdb3.conv1.bias\", \"body.22.rdb3.conv2.weight\", \"body.22.rdb3.conv2.bias\", \"body.22.rdb3.conv3.weight\", \"body.22.rdb3.conv3.bias\", \"body.22.rdb3.conv4.weight\", \"body.22.rdb3.conv4.bias\", \"body.22.rdb3.conv5.weight\", \"body.22.rdb3.conv5.bias\", \"conv_body.weight\", \"conv_body.bias\", \"conv_up1.weight\", \"conv_up1.bias\", \"conv_up2.weight\", \"conv_up2.bias\", \"conv_hr.weight\", \"conv_hr.bias\", \"conv_last.weight\", \"conv_last.bias\". \n\tUnexpected key(s) in state_dict: \"params_ema\". "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToPILImage, ToTensor, Normalize\n",
    "from basicsr.archs.rrdbnet_arch import RRDBNet\n",
    "from basicsr.utils import imwrite\n",
    "\n",
    "def resize_image(input_path, size=(224, 224)):\n",
    "    # Abrir la imagen\n",
    "    image = Image.open(input_path).convert(\"L\")  # Convertir a escala de grises\n",
    "    \n",
    "    # Obtener tamaño original\n",
    "    original_width, original_height = image.size\n",
    "    aspect_ratio = original_width / original_height\n",
    "    \n",
    "    # Calcular nuevo tamaño\n",
    "    if aspect_ratio > 1:\n",
    "        # Imagen más ancha que alta\n",
    "        new_width = size[0]\n",
    "        new_height = int(new_width / aspect_ratio)\n",
    "    else:\n",
    "        # Imagen más alta que ancha\n",
    "        new_height = size[1]\n",
    "        new_width = int(new_height * aspect_ratio)\n",
    "    \n",
    "    # Redimensionar la imagen manteniendo la relación de aspecto\n",
    "    # si la imagen es mas chica que el tamaño deseado, uso interpolación LANCZOS, sino LINEAL\n",
    "    if original_width < size[0] or original_height < size[1]:\n",
    "        resized_image = image.resize((new_width, new_height), Image.LANCZOS)\n",
    "    else:\n",
    "        resized_image = image.resize((new_width, new_height), Image.LINEAR)\n",
    "    \n",
    "    # Crear un nuevo fondo de 224x224 y pegar la imagen redimensionada en el centro\n",
    "    new_image = Image.new(\"L\", size)\n",
    "    new_image.paste(resized_image, ((size[0] - new_width) // 2, (size[1] - new_height) // 2))\n",
    "    \n",
    "    return new_image\n",
    "\n",
    "def super_resolve_image(image, model, device):\n",
    "    # Convertir imagen a tensor y normalizar\n",
    "    image = ToTensor()(image).unsqueeze(0).to(device)\n",
    "    image = image.repeat(1, 3, 1, 1)  # Convertir a 3 canales replicando el canal de grises\n",
    "    \n",
    "    # Aumentar la resolución usando el modelo de super-resolución\n",
    "    with torch.no_grad():\n",
    "        sr_image = model(image)\n",
    "    \n",
    "    # Convertir de nuevo a PIL y a escala de grises\n",
    "    sr_image = sr_image.squeeze(0).cpu()\n",
    "    sr_image = ToPILImage()(sr_image[0])  # Convertir solo el primer canal a escala de grises\n",
    "    \n",
    "    return sr_image\n",
    "\n",
    "def process_image(input_path, output_path, model_path):\n",
    "    # Configuración del dispositivo\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Paso 1: Redimensionar la imagen manteniendo la relación de aspecto\n",
    "    resized_image = resize_image(input_path, size=(224, 224))\n",
    "    \n",
    "    # Cargar el modelo de super-resolución ESRGAN\n",
    "    model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32, scale=4)\n",
    "    model.load_state_dict(torch.load(model_path), strict=True)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Paso 2: Mejorar la resolución de la imagen redimensionada\n",
    "    final_image = super_resolve_image(resized_image, model, device)\n",
    "    \n",
    "    # Guardar la imagen final\n",
    "    final_image.save(output_path)\n",
    "\n",
    "# Ejemplo de uso\n",
    "process_image(\"CelebA/celebA/img_align_celeba/img_align_celeba/125479.jpg\", \"ESRGAN_output_image.jpg\", \"RealESRGAN_x4plus.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
